# üéØ Checklist para Treinar no Kaggle (T4 x2)

**Hardware:** 2x NVIDIA T4 (16GB VRAM cada)  
**Backend:** CUDA (Burn Framework)  
**Modelos alvo:** 400m, 800m

---

## üìã Pr√©-requisitos

### 1. Ambiente Local (Prepara√ß√£o)

- [x] ‚úÖ Build CPU funciona localmente
  ```bash
  # Windows
  .\build_test_cpu.ps1
  
  # Linux/Mac
  ./build_test_cpu.sh
  ```

- [x] ‚úÖ Bin√°rio compilado sem erros
- [x] ‚úÖ Testes b√°sicos passando (85m, 400m)

### 2. Dados Preparados

- [ ] ‚úÖ `tokenizer.json` pronto
- [ ] ‚úÖ `train.bin` pronto (dataset tokenizado)
- [ ] ‚úÖ Dataset criado no Kaggle com esses arquivos

---

## üöÄ Setup no Kaggle

### 1. Criar Dataset no Kaggle

```python
# No notebook do Kaggle
# Upload dos arquivos:
# - tokenizer.json
# - train.bin
```

### 2. Clone Reposit√≥rio

```bash
# No notebook Kaggle
!git clone https://github.com/seu-usuario/ptbr-slm.git
%cd ptbr-slm
```

### 3. Build CUDA

```bash
# Instalar Rust (se necess√°rio)
!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
!source $HOME/.cargo/env

# Build com CUDA
!cargo build --release --features cuda
```

**Tempo esperado:** 10-20 minutos  
**Espa√ßo necess√°rio:** ~2-3 GB

### 4. Verificar GPU

```bash
!nvidia-smi
```

**Esperado:** 2 GPUs T4 vis√≠veis

---

## üèãÔ∏è Treinamento

### Configura√ß√£o Recomendada por Modelo

#### **Modelo 400m** (400M par√¢metros)

```bash
./target/release/ptbr-slm train \
  --data /kaggle/input/seu-dataset \
  --tokenizer /kaggle/input/seu-dataset/tokenizer.json \
  --output /kaggle/working/checkpoints \
  --model-size 400m \
  --batch-size 2 \
  --grad-accum 16 \
  --seq-len 256 \
  --max-steps 50000 \
  --learning-rate 3e-4 \
  --warmup-steps 500 \
  --save-every 2500 \
  --log-every 100 \
  --eval-every 1000 \
  --eval-samples 100
```

**Estimativas:**
- VRAM por GPU: ~8-10 GB
- Tempo: ~10-15 horas (T4 x2)
- Checkpoints: ~200 MB cada

#### **Modelo 800m** (800M par√¢metros)

```bash
./target/release/ptbr-slm train \
  --data /kaggle/input/seu-dataset \
  --tokenizer /kaggle/input/seu-dataset/tokenizer.json \
  --output /kaggle/working/checkpoints \
  --model-size 800m \
  --batch-size 1 \
  --grad-accum 32 \
  --seq-len 256 \
  --max-steps 50000 \
  --learning-rate 3e-4 \
  --warmup-steps 500 \
  --save-every 2500 \
  --log-every 100 \
  --eval-every 1000 \
  --eval-samples 100
```

**Estimativas:**
- VRAM por GPU: ~12-14 GB (pode ser apertado!)
- Tempo: ~15-20 horas (T4 x2)
- Checkpoints: ~400 MB cada

**‚ö†Ô∏è ATEN√á√ÉO:** 800m pode n√£o caber em T4 se `seq_len > 256`!

---

## ‚ö†Ô∏è Problemas Comuns e Solu√ß√µes

### 1. **Out of Memory (OOM) - 800m**

**Sintomas:**
```
CUDA out of memory: Tried to allocate X MB
```

**Solu√ß√µes:**
- ‚úÖ Reduzir `--batch-size` para 1
- ‚úÖ Reduzir `--seq-len` para 128 ou 192
- ‚úÖ Aumentar `--grad-accum` para compensar batch menor
- ‚úÖ Verificar se est√° usando apenas 1 GPU (devido CUDA_VISIBLE_DEVICES)

### 2. **Build Muito Lento no Kaggle**

**Solu√ß√£o:**
```bash
# Usar mais jobs paralelos
!CARGO_BUILD_JOBS=4 cargo build --release --features cuda
```

### 3. **CUDA Device Not Found**

**Verificar:**
```bash
!nvidia-smi
!echo $CUDA_VISIBLE_DEVICES
```

**Corre√ß√£o:**
```bash
# O c√≥digo define CUDA_VISIBLE_DEVICES="0" por padr√£o
# Para usar ambas GPUs, seria necess√°rio implementar DataParallel
# Por enquanto, apenas GPU 0 √© usada (que √© suficiente para treino)
# Para usar GPU 1, mude para CudaDevice::new(1) no c√≥digo
```

### 4. **Erro de Compila√ß√£o CUDA**

**Poss√≠veis causas:**
- CUDA toolkit n√£o instalado no Kaggle
- Vers√£o incompat√≠vel

**Solu√ß√£o:**
```bash
# Verificar CUDA
!nvcc --version

# Se necess√°rio, instalar CUDA toolkit
!apt-get update
!apt-get install -y cuda-toolkit-11-8
```

---

## üìä Monitoramento

### Durante Treinamento

```bash
# Em outro terminal/celula
watch -n 1 nvidia-smi
```

**M√©tricas a observar:**
- GPU Utilization: ~80-100%
- GPU Memory: < 16GB por GPU
- Temperature: < 80¬∞C

### Logs de Treinamento

Os logs s√£o salvos em `metrics.csv`:
```csv
step,loss,ppl,lr,grad_norm,tokens_per_sec,train_time,eval_loss,eval_ppl
```

---

## üíæ Gerenciamento de Checkpoints

### Limite de Espa√ßo Kaggle

Kaggle tem limite de **20GB** para `/kaggle/working/`

**Estrat√©gias:**
1. Salvar apenas checkpoints finais (√∫ltimos 2-3)
2. Download peri√≥dico de checkpoints importantes
3. Usar `--save-every` maior para economizar espa√ßo

### Download de Checkpoints

```python
# No notebook Kaggle
import shutil

# Comprimir checkpoint
shutil.make_archive('checkpoint_25000', 'zip', '/kaggle/working/checkpoints/checkpoint_25000')
```

---

## üîç Debug e Troubleshooting

### Teste R√°pido (Modelo Pequeno)

Antes de treinar modelo grande, teste com 85m:

```bash
./target/release/ptbr-slm train \
  --data /kaggle/input/seu-dataset \
  --tokenizer /kaggle/input/seu-dataset/tokenizer.json \
  --output /kaggle/working/test \
  --model-size 85m \
  --max-steps 100 \
  --batch-size 4
```

Se 85m funciona, ent√£o o problema √© espec√≠fico do modelo grande.

### Verificar Configura√ß√£o do Modelo

```bash
./target/release/ptbr-slm info --model-size 800m
```

**Verificar:**
- VRAM estimada < 16GB
- Par√¢metros corretos

---

## üìù Notas Finais

1. **Kaggle tem timeout:** Notebooks param ap√≥s 9 horas de execu√ß√£o
   - Para treinos longos, use Kaggle Scripts ou divida em m√∫ltiplas sess√µes

2. **Multi-GPU:** Burn/CUDA suporta apenas 1 GPU por padr√£o
   - Para usar 2 GPUs, seria necess√°rio implementar DataParallel
   - Por enquanto, use apenas GPU 0 ou ajuste c√≥digo

3. **Checkpoints:** Salve frequentemente (--save-every 2500)
   - Kaggle pode crashar a qualquer momento

4. **Logs:** Monitore `metrics.csv` e stdout
   - Loss deve diminuir
   - PPL deve melhorar

---

## ‚úÖ Checklist Final

- [ ] Build CUDA funciona no Kaggle
- [ ] Teste com 85m passa
- [ ] GPU detectada corretamente
- [ ] Dataset carregado e verificado
- [ ] Configura√ß√£o de treinamento ajustada (batch, seq_len)
- [ ] Monitoramento configurado
- [ ] Plano de download de checkpoints definido

**Boa sorte com o treinamento! üöÄ**
