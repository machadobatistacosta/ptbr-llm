# üêõ Debug: Treino Morre Antes do Primeiro Step

## Problema
O treino inicia mas morre antes de completar o primeiro step, sem mensagens de erro claras.

## Corre√ß√µes Aplicadas

### 1. Valida√ß√µes de Batch
- ‚úÖ Verifica se batch est√° vazio
- ‚úÖ Verifica se sequ√™ncias t√™m tamanho v√°lido
- ‚úÖ Verifica se todas as sequ√™ncias t√™m o mesmo tamanho

### 2. Logs Detalhados de Debug
- ‚úÖ Log do primeiro batch com informa√ß√µes detalhadas
- ‚úÖ Log antes e depois de criar tensores
- ‚úÖ Log antes de iniciar train_step

### 3. Tratamento de Erros
- ‚úÖ Mensagens de erro mais descritivas
- ‚úÖ Continua processamento se batch for inv√°lido (em vez de crashar)

## Como Usar no Kaggle

### 1. Atualizar C√≥digo
```python
%cd ptbr-llm  # Magic command - muda diret√≥rio permanentemente
!git pull
```

### 2. Rebuild
```python
import os
os.environ["PATH"] = f"{os.environ['HOME']}/.cargo/bin:" + os.environ["PATH"]

%cd ptbr-llm
!CARGO_BUILD_JOBS=4 cargo build --release --features cuda
```

### 3. Rodar com Backtrace Completo
```python
import os
os.environ["RUST_BACKTRACE"] = "full"
os.environ["PATH"] = f"{os.environ['HOME']}/.cargo/bin:" + os.environ["PATH"]

%cd ptbr-llm
!RUST_BACKTRACE=full ./target/release/ptbr-slm train \
  --data /kaggle/input/ptbr-v16-ready/tokenized_v16_full \
  --tokenizer /kaggle/input/ptbr-v16-ready/tokenizer_v16_full/tokenizer.json \
  --output /kaggle/working/checkpoints \
  --model-size 400m \
  --batch-size 1 \
  --grad-accum 4 \
  --seq-len 128 \
  --max-steps 10 \
  --learning-rate 3e-4 \
  --warmup-steps 2 \
  --save-every 100 \
  --eval-every 100
```

## O Que Esperar

### Se Funcionar:
```
  üì¶ Processando 5000000 batches no primeiro epoch...
  üîç Debug: Primeiro batch - 1 sequ√™ncias, seq_len=128
  üîç Debug: Criando tensores para batch 1...
  üîç Debug: Tensores criados, iniciando train_step...
  ‚úÖ Primeiro step completo! Loss inicial: X.XXXX
  Step      1 | Loss: X.XXXX | ...
```

### Se Falhar:
Voc√™ ver√° logs detalhados indicando exatamente onde falhou:
- ‚ùå Se falhar ao criar tensor: ver√° "ERRO ao criar input_tensor"
- ‚ùå Se falhar no train_step: ver√° backtrace completo do Rust
- ‚ö†Ô∏è Se batch inv√°lido: ver√° aviso e continua

## Poss√≠veis Causas

### 1. Mem√≥ria GPU Insuficiente
**Sintoma**: Crash durante `train_step`  
**Solu√ß√£o**: Reduzir `batch-size` e `seq-len`
```bash
--batch-size 1 --seq-len 64
```

### 2. Dataset Corrompido
**Sintoma**: Erro ao criar tensor ou batch inv√°lido  
**Solu√ß√£o**: Verificar dataset:
```python
import os
path = "/kaggle/input/ptbr-v16-ready/tokenized_v16_full/train.bin"
size = os.path.getsize(path)
print(f"Tamanho: {size / (1024**3):.2f} GB")
print(f"Tokens estimados: {(size // 2) / 1e9:.2f}B")
```

### 3. Formato de Dados Inv√°lido
**Sintoma**: Erro "sequ√™ncias de tamanhos diferentes"  
**Solu√ß√£o**: Re-tokenizar dataset ou verificar `seq_len` do dataset

### 4. Problema com CUDA
**Sintoma**: Crash silencioso sem mensagens  
**Solu√ß√£o**: Testar GPU primeiro:
```bash
!cd ptbr-llm && ./target/release/ptbr-slm test-gpu --model-size 400m
```

## Debug Passo a Passo

### Passo 1: Verificar GPU
```python
!nvidia-smi
```

### Passo 2: Testar GPU com Modelo
```python
%cd ptbr-llm
!./target/release/ptbr-slm test-gpu --model-size 400m
```

### Passo 3: Verificar Dataset
```python
%cd ptbr-llm
!./target/release/ptbr-slm info \
  --data /kaggle/input/ptbr-v16-ready/tokenized_v16_full
```

### Passo 4: Treino M√≠nimo com Logs
```python
import os
os.environ["RUST_BACKTRACE"] = "full"
os.environ["PATH"] = f"{os.environ['HOME']}/.cargo/bin:" + os.environ["PATH"]

%cd ptbr-llm
!RUST_BACKTRACE=full ./target/release/ptbr-slm train \
  --data /kaggle/input/ptbr-v16-ready/tokenized_v16_full \
  --tokenizer /kaggle/input/ptbr-v16-ready/tokenizer_v16_full/tokenizer.json \
  --output /kaggle/working/checkpoints \
  --model-size 400m \
  --batch-size 1 \
  --grad-accum 1 \
  --seq-len 64 \
  --max-steps 1 \
  --learning-rate 3e-4 \
  --warmup-steps 1 \
  --save-every 100 \
  --eval-every 100
```

## Informa√ß√µes para Reportar Bug

Se ainda falhar, colete estas informa√ß√µes:

1. **Output completo** do comando com `RUST_BACKTRACE=full`
2. **Output de `nvidia-smi`**
3. **Output de `test-gpu`**
4. **Tamanho do dataset** (GB)
5. **Configura√ß√£o exata** usada (batch-size, seq-len, etc.)

## Pr√≥ximos Passos

1. ‚úÖ Atualizar c√≥digo no Kaggle
2. ‚úÖ Rebuild
3. ‚úÖ Rodar com `RUST_BACKTRACE=full`
4. ‚úÖ Analisar logs detalhados
5. ‚úÖ Identificar causa raiz
6. ‚úÖ Aplicar corre√ß√£o espec√≠fica
