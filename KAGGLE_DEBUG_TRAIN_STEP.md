# ğŸ› Debug: Treino Morre no train_step

## Problema
O treino morre silenciosamente logo apÃ³s "Tensores criados, iniciando train_step..." sem mensagens de erro.

## CorreÃ§Ãµes Aplicadas

### Logs Detalhados no train_step
Adicionei logs em cada etapa do `train_step` para identificar exatamente onde estÃ¡ falhando:

1. âœ… Log antes de `model.forward()`
2. âœ… Log apÃ³s `model.forward()` com shape do resultado
3. âœ… Log antes e apÃ³s cÃ¡lculo de loss
4. âœ… Log antes e apÃ³s `backward()`
5. âœ… Log antes e apÃ³s `optimizer.step()`

## Como Usar no Kaggle

### 1. Atualizar CÃ³digo
```python
%cd ptbr-llm  # Se jÃ¡ estiver no diretÃ³rio, pode pular
!git pull
```

### 2. Rebuild
```python
import os
os.environ["PATH"] = f"{os.environ['HOME']}/.cargo/bin:" + os.environ["PATH"]

%cd ptbr-llm
!CARGO_BUILD_JOBS=4 cargo build --release --features cuda
```

### 3. Rodar Treino com Debug
```python
import os
os.environ["RUST_BACKTRACE"] = "full"

%cd ptbr-llm
!RUST_BACKTRACE=full ./target/release/ptbr-slm train \
  --data /kaggle/input/ptbr-v16-ready/tokenized_v16_full \
  --tokenizer /kaggle/input/ptbr-v16-ready/tokenizer_v16_full/tokenizer.json \
  --output /kaggle/working/checkpoints \
  --model-size 400m \
  --batch-size 1 \
  --grad-accum 1 \
  --seq-len 64 \
  --max-steps 1 \
  --learning-rate 3e-4 \
  --warmup-steps 1 \
  --save-every 100 \
  --eval-every 100
```

## O Que VocÃª VerÃ¡ Agora

### Se Funcionar:
```
  ğŸ” Debug: Primeiro batch - 1 sequÃªncias, seq_len=64
  ğŸ” Debug: Criando tensores para batch 1...
  ğŸ” Debug: Tensores criados, iniciando train_step...
  ğŸ” Debug train_step: Iniciando forward...
  ğŸ” Debug train_step: Chamando model.forward...
  ğŸ” Debug train_step: Forward completo, shape: [1, 64, 32000]
  ğŸ” Debug train_step: Calculando loss...
  ğŸ” Debug train_step: Loss calculado: X.XXXX
  ğŸ” Debug train_step: Iniciando backward...
  ğŸ” Debug train_step: Backward completo
  ğŸ” Debug train_step: GradParams criado
  ğŸ” Debug train_step: Completou gradient accumulation, fazendo optimizer step...
  ğŸ” Debug train_step: Chamando optimizer.step...
  ğŸ” Debug train_step: Optimizer step completo!
  âœ… Primeiro step completo! Loss inicial: X.XXXX
```

### Se Falhar:
VocÃª verÃ¡ exatamente onde parou:
- Se parar em "Chamando model.forward..." â†’ problema no forward
- Se parar em "Calculando loss..." â†’ problema no cÃ¡lculo de loss
- Se parar em "Iniciando backward..." â†’ problema no backward
- Se parar em "Chamando optimizer.step..." â†’ problema no optimizer

## PossÃ­veis Causas

### 1. Problema no Forward (model.forward)
**Sintoma**: Para em "Chamando model.forward..."  
**Causas possÃ­veis**:
- MemÃ³ria GPU insuficiente
- Erro na compilaÃ§Ã£o CUDA JIT
- Problema com dimensÃµes do tensor

**SoluÃ§Ã£o**:
- Reduzir `seq-len` para 32 ou 16
- Reduzir `batch-size` para 1
- Verificar memÃ³ria GPU: `!nvidia-smi`

### 2. Problema no Backward
**Sintoma**: Para em "Iniciando backward..."  
**Causas possÃ­veis**:
- MemÃ³ria GPU insuficiente para gradientes
- Erro na computaÃ§Ã£o de gradientes

**SoluÃ§Ã£o**:
- Reduzir ainda mais `seq-len`
- Verificar se hÃ¡ outros processos usando GPU

### 3. Problema no Optimizer
**Sintoma**: Para em "Chamando optimizer.step..."  
**Causas possÃ­veis**:
- Erro ao atualizar parÃ¢metros
- Problema com estado do optimizer

**SoluÃ§Ã£o**:
- Verificar logs completos com `RUST_BACKTRACE=full`
- Tentar com `grad-accum=1` para simplificar

## Debug Passo a Passo

### Passo 1: Verificar MemÃ³ria GPU
```python
!nvidia-smi
```

### Passo 2: Teste GPU (deve funcionar)
```python
%cd ptbr-llm
!./target/release/ptbr-slm test-gpu --model-size 400m
```

### Passo 3: Treino MÃ­nimo Absoluto
```python
import os
os.environ["RUST_BACKTRACE"] = "full"

%cd ptbr-llm
!RUST_BACKTRACE=full ./target/release/ptbr-slm train \
  --data /kaggle/input/ptbr-v16-ready/tokenized_v16_full \
  --tokenizer /kaggle/input/ptbr-v16-ready/tokenizer_v16_full/tokenizer.json \
  --output /kaggle/working/checkpoints \
  --model-size 400m \
  --batch-size 1 \
  --grad-accum 1 \
  --seq-len 32 \
  --max-steps 1 \
  --learning-rate 3e-4 \
  --warmup-steps 1 \
  --save-every 100 \
  --eval-every 100
```

### Passo 4: Analisar Logs
Procure pela Ãºltima mensagem de debug que apareceu. Isso indica onde estÃ¡ falhando.

## Nota sobre DiretÃ³rio Aninhado

Se vocÃª ver `/kaggle/working/ptbr-llm/ptbr-llm/ptbr-llm/...`, isso significa que o `%cd` estÃ¡ sendo executado mÃºltiplas vezes ou o clone criou diretÃ³rios aninhados.

**SoluÃ§Ã£o**: Use caminho absoluto ou verifique onde estÃ¡:
```python
!pwd
!ls -la
```

Se necessÃ¡rio, limpe e clone novamente:
```python
!rm -rf ptbr-llm
!git clone https://github.com/machadobatistacosta/ptbr-llm.git
%cd ptbr-llm
```

## PrÃ³ximos Passos

1. âœ… Atualizar cÃ³digo
2. âœ… Rebuild
3. âœ… Rodar treino mÃ­nimo com `RUST_BACKTRACE=full`
4. âœ… Identificar Ãºltima mensagem de debug
5. âœ… Reportar onde parou para diagnÃ³stico especÃ­fico
