# ğŸš€ Quick Start - Kaggle T4 x2

Guia rÃ¡pido para treinar 400m/800m no Kaggle.

---

## âš¡ Setup RÃ¡pido (5 min)

### 1. No Notebook Kaggle

```bash
# Clone repo (ajuste a URL)
!git clone https://github.com/seu-usuario/ptbr-slm.git
%cd ptbr-slm

# Execute setup
!bash kaggle_setup.sh
```

### 2. Verificar GPU

```bash
!nvidia-smi
```

**Esperado:** 2 GPUs T4, 16GB cada

---

## ğŸ“¦ Build Local (Antes de ir para Kaggle)

### Windows
```powershell
.\build_test_cpu.ps1
```

### Linux/Mac
```bash
chmod +x build_test_cpu.sh
./build_test_cpu.sh
```

**Objetivo:** Garantir que o cÃ³digo compila e funciona antes de perder tempo no Kaggle.

---

## ğŸ¯ Comandos de Treinamento

### Modelo 400m (Recomendado para comeÃ§ar)

```bash
./target/release/ptbr-slm train \
  --data /kaggle/input/seu-dataset \
  --tokenizer /kaggle/input/seu-dataset/tokenizer.json \
  --output /kaggle/working/checkpoints \
  --model-size 400m \
  --batch-size 2 \
  --grad-accum 16 \
  --seq-len 256 \
  --max-steps 50000 \
  --save-every 2500
```

**VRAM esperada:** ~8-10 GB  
**Status:** âœ… Seguro em T4

### Modelo 800m (AtenÃ§Ã£o!)

```bash
./target/release/ptbr-slm train \
  --data /kaggle/input/seu-dataset \
  --tokenizer /kaggle/input/seu-dataset/tokenizer.json \
  --output /kaggle/working/checkpoints \
  --model-size 800m \
  --batch-size 1 \
  --grad-accum 32 \
  --seq-len 256 \
  --max-steps 50000 \
  --save-every 2500
```

**VRAM esperada:** ~12-14 GB  
**Status:** âš ï¸ Pode dar OOM! Se der erro, reduza `--seq-len` para 128

---

## ğŸ” Verificar Requisitos

```bash
# Ver info do modelo
./target/release/ptbr-slm info --model-size 800m

# Teste rÃ¡pido (100 steps)
./target/release/ptbr-slm train \
  --data /kaggle/input/seu-dataset \
  --tokenizer /kaggle/input/seu-dataset/tokenizer.json \
  --output /kaggle/working/test \
  --model-size 400m \
  --max-steps 100 \
  --batch-size 2
```

---

## âš ï¸ Problemas Comuns

### 1. Out of Memory (800m)

**SoluÃ§Ã£o:**
```bash
# Reduzir seq_len
--seq-len 128  # ao invÃ©s de 256

# OU reduzir batch
--batch-size 1 --grad-accum 64
```

### 2. Build muito lento

**SoluÃ§Ã£o:**
```bash
# Mais jobs paralelos
CARGO_BUILD_JOBS=4 cargo build --release --features cuda
```

### 3. CUDA nÃ£o encontrado

**Verificar:**
```bash
!nvcc --version
!nvidia-smi
```

**Burn usa CUDA JIT** - nÃ£o precisa de CUDA toolkit instalado separadamente!

---

## ğŸ“Š Backend: CUDA vs WGPU

### Kaggle usa NVIDIA T4 â†’ **CUDA**

O projeto suporta ambos:
- **CUDA** (`--features cuda`): Para NVIDIA GPUs (Kaggle) âœ…
- **WGPU** (`--features gpu`): Para outras GPUs (Vulkan/Metal/DX12)
- **CPU** (`--features cpu`): Para testes locais

**No Kaggle, sempre use: `--features cuda`**

---

## ğŸ“ˆ Estimativas de Tempo

| Modelo | Batch | Seq Len | VRAM | Tempo (T4 x1) |
|--------|-------|---------|------|---------------|
| 400m | 2 | 256 | ~8GB | ~10-15h |
| 800m | 1 | 256 | ~12GB | ~15-20h |
| 800m | 1 | 128 | ~10GB | ~12-15h |

**Nota:** Kaggle permite 9h contÃ­nuas. Para treinos mais longos, divida em sessÃµes ou use Kaggle Scripts.

---

## ğŸ’¾ EspaÃ§o e Checkpoints

**Kaggle Working:** 20GB limite

- Checkpoint 400m: ~200 MB
- Checkpoint 800m: ~400 MB

**EstratÃ©gia:**
- Salvar apenas Ãºltimos 2-3 checkpoints
- Download periÃ³dico dos importantes
- `--save-every 2500` Ã© razoÃ¡vel

---

## âœ… Checklist Final

- [ ] Build CPU local funciona
- [ ] Dataset no Kaggle com tokenizer.json + train.bin
- [ ] Build CUDA no Kaggle concluÃ­do
- [ ] Teste rÃ¡pido (100 steps) passou
- [ ] GPU detectada corretamente
- [ ] ConfiguraÃ§Ã£o ajustada (batch, seq_len)
- [ ] Monitoramento configurado (nvidia-smi)

**Boa sorte! ğŸš€**
