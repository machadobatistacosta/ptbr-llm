# ğŸ“‹ Resumo - PreparaÃ§Ã£o para Kaggle

## âœ… O que foi feito

1. âœ… **Scripts de build/teste local criados**
   - `build_test_cpu.ps1` (Windows)
   - `build_test_cpu.sh` (Linux/Mac)
   - Testa modelos 85m e 400m localmente antes de ir para Kaggle

2. âœ… **Scripts de setup para Kaggle**
   - `kaggle_setup.sh` - Setup automÃ¡tico no Kaggle
   - `check_vram_requirements.sh` - Verifica requisitos de VRAM

3. âœ… **DocumentaÃ§Ã£o completa**
   - `KAGGLE_CHECKLIST.md` - Checklist detalhado
   - `KAGGLE_QUICK_START.md` - Guia rÃ¡pido

---

## ğŸ¯ Backend: CUDA (NVIDIA T4)

**Resposta:** O Kaggle usa **CUDA** (nÃ£o WGPU).

- Kaggle tem GPUs NVIDIA â†’ CUDA Ã© o backend certo
- Build: `cargo build --release --features cuda`
- Burn framework suporta CUDA JIT (nÃ£o precisa CUDA toolkit separado)

---

## âš ï¸ Problemas com 800m/400m

### **400m** âœ… Seguro
- VRAM: ~8-10 GB (cabe fÃ¡cil em T4 16GB)
- Batch: 2, Seq Len: 256
- **Sem problemas esperados**

### **800m** âš ï¸ Pode dar OOM
- VRAM: ~12-14 GB (apertado em T4)
- Batch: 1, Seq Len: 256 pode nÃ£o caber
- **SoluÃ§Ã£o:** Reduzir `--seq-len` para 128

**FÃ³rmula de VRAM:**
```
VRAM = ParÃ¢metros * 4 (FP32) + AtivaÃ§Ãµes + Gradientes + Optimizer
```

Aumentar `seq_len` ou `batch_size` aumenta ativaÃ§Ãµes drasticamente!

---

## ğŸ”§ Ajustes NecessÃ¡rios

### 1. Multi-GPU

**SituaÃ§Ã£o atual:**
- CÃ³digo usa apenas GPU 0 (`CudaDevice::new(0)`)
- T4 x2 disponÃ­vel, mas apenas 1 GPU usada

**SoluÃ§Ã£o temporÃ¡ria:**
- Usar apenas 1 GPU por vez Ã© suficiente
- Para usar GPU 1: mudar `CudaDevice::new(0)` â†’ `CudaDevice::new(1)`

**SoluÃ§Ã£o futura:**
- Implementar DataParallel para usar ambas GPUs
- Requer mudanÃ§as significativas no cÃ³digo

### 2. OOM em 800m

**Ajustes no cÃ³digo (se necessÃ¡rio):**
- Reduzir `max_seq_len` padrÃ£o de 512 para 256 em `ptbr_800m()`
- JÃ¡ estÃ¡ configurado para 512, mas pode reduzir mais

**SoluÃ§Ã£o imediata:**
- Usar `--seq-len 128` na linha de comando
- Funciona sem mudar cÃ³digo

---

## ğŸ“ PrÃ³ximos Passos

1. **Teste local (agora):**
   ```powershell
   .\build_test_cpu.ps1
   ```

2. **No Kaggle:**
   ```bash
   !bash kaggle_setup.sh
   !./target/release/ptbr-slm info --model-size 400m
   ```

3. **Treino:**
   - ComeÃ§ar com 400m (mais seguro)
   - Depois tentar 800m com seq_len reduzido

---

## ğŸ“Š ConfiguraÃ§Ãµes Recomendadas

| Modelo | Batch | Grad Accum | Seq Len | VRAM | Status |
|--------|-------|------------|---------|------|--------|
| **400m** | 2 | 16 | 256 | ~8GB | âœ… OK |
| **800m** | 1 | 32 | 256 | ~12GB | âš ï¸ Apertado |
| **800m** | 1 | 32 | 128 | ~10GB | âœ… Seguro |

---

## ğŸš€ Comando Final

```bash
# Build no Kaggle
cargo build --release --features cuda

# Treinar 400m
./target/release/ptbr-slm train \
  --data /kaggle/input/seu-dataset \
  --tokenizer /kaggle/input/seu-dataset/tokenizer.json \
  --output /kaggle/working/checkpoints \
  --model-size 400m \
  --batch-size 2 \
  --grad-accum 16 \
  --seq-len 256 \
  --max-steps 50000
```

---

**Tudo pronto! Pode comeÃ§ar o teste local e depois partir para o Kaggle! ğŸ‰**
